{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Feature Engineering\n",
    "\n",
    "# We will perform feature engineering for the getINNOtized recommendation system. I will create features for collaborative- and content-based filtering:\n",
    "# - **User-Item Interaction Matrix**: A weighted matrix of user-item interactions (view=1, addtocart=3, transaction=5).\n",
    "# - **Item Features**: Incorporating category depth from `category_tree.csv`.\n",
    "# - **Category Features**: Incorporating category depth from `category_tree.csv`, to enhance diversity in recommendations.\n",
    "\n",
    "# These features will support modeling to answer the seven business questions: personalization, conversion optimization, seasonal trends, popularity, diversity, and algorithm performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "preprocessed_data_dir = \"../data/preprocessed_data/\"\n",
    "raw_data_dir = \"../data/\"\n",
    "\n",
    "# Load preprocessed data\n",
    "events = pd.read_csv(os.path.join(raw_data_dir, \"events.csv\"))\n",
    "user_behavior = pd.read_csv(os.path.join(preprocessed_data_dir, \"user_behavior.csv\"))\n",
    "item_properties_part1 = pd.read_csv(os.path.join(raw_data_dir, \"item_properties_part1.csv\"))\n",
    "item_properties_part2 = pd.read_csv(os.path.join(raw_data_dir, \"item_properties_part2.csv\"))\n",
    "category_tree = pd.read_csv(os.path.join(raw_data_dir, \"category_tree.csv\"))\n",
    "\n",
    "# Concatenate item properties\n",
    "item_properties = pd.concat([item_properties_part1, item_properties_part2])\n",
    "\n",
    "# Load user and item ID mappings\n",
    "user_ids = pd.read_csv(os.path.join(preprocessed_data_dir, \"user_ids.csv\"))\n",
    "item_ids = pd.read_csv(os.path.join(preprocessed_data_dir, \"item_ids.csv\"))\n",
    "\n",
    "# Convert to dictionary for mapping\n",
    "user_ids = user_ids[\"0\"].to_dict()\n",
    "item_ids = item_ids[\"0\"].to_dict()\n",
    "\n",
    "# Reverse the mappings for lookup\n",
    "user_id_to_idx = {k: v for k, v in user_ids.items()}\n",
    "item_id_to_idx = {k: v for k, v in item_ids.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item Interaction Matrix\n",
    "\n",
    "# We will create a sparse user-item interaction matrix where rows are users (visitorid), columns are items (itemid), and values are weighted interaction scores:\n",
    "# - View: 1\n",
    "# - Add to Cart: 3\n",
    "# - Transaction: 5\n",
    "\n",
    "# This matrix will be used for collaborative filtering to personalize recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix saved. Rating distribution:\n",
      "rating\n",
      "1    719082\n",
      "2     48417\n",
      "5     18494\n",
      "3     17191\n",
      "4      8315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply anomaly filtering\n",
    "normal_users = user_behavior[user_behavior['events_per_day'] <= 100]['visitorid'].to_list()\n",
    "events = events[events['visitorid'].isin(normal_users)]\n",
    "\n",
    "# Map event types to weights\n",
    "event_weights = {'view': 1, 'addtocart': 3, 'transaction': 5}\n",
    "events['rating'] = events['event'].map(event_weights)\n",
    "\n",
    "# Aggregate ratings by user and item\n",
    "interactions = events.groupby(['visitorid', 'itemid'])['rating'].sum().reset_index()\n",
    "\n",
    "# Map to indices\n",
    "interactions['user_idx'] = interactions['visitorid'].map(user_id_to_idx)\n",
    "interactions['item_idx'] = interactions['itemid'].map(item_id_to_idx)\n",
    "\n",
    "# Remove unmapped entries\n",
    "interactions = interactions.dropna(subset=['user_idx', 'item_idx'])\n",
    "interactions['user_idx'] = interactions['user_idx'].astype(int)\n",
    "interactions['item_idx'] = interactions['item_idx'].astype(int)\n",
    "\n",
    "# Cap ratings at 5\n",
    "interactions['rating'] = np.minimum(interactions['rating'], 5)\n",
    "\n",
    "# Create sparse matrix\n",
    "rows = interactions['user_idx'].values\n",
    "cols = interactions['item_idx'].values\n",
    "data = interactions['rating'].values\n",
    "user_item_matrix = coo_matrix((data, (rows, cols)), shape=(len(user_ids), len(item_ids)))\n",
    "\n",
    "# Save the sparse matrix\n",
    "with open(os.path.join(preprocessed_data_dir, \"user_item_sparse.pkl\"), \"wb\") as f:\n",
    "    joblib.dump(user_item_matrix, f)\n",
    "\n",
    "print(\"Sparse matrix saved. Rating distribution:\")\n",
    "print(interactions['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Features\n",
    "\n",
    "# I will extract item features from `item_properties_part1.csv` and `item_properties_part2.csv`.\n",
    "\n",
    "# **Category**: The `categoryid` property for each item.\n",
    "\n",
    "# These features will be used for content-based filtering to optimize conversion rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features saved:    item_idx  categoryid\n",
      "0         0         209\n",
      "1         1        1114\n",
      "2         2        1305\n",
      "3         3        1171\n",
      "4         4        1038\n"
     ]
    }
   ],
   "source": [
    "# Filter properties to get categoryid\n",
    "category_properties = item_properties[item_properties['property'] == 'categoryid'].copy()\n",
    "\n",
    "# Convert value to numeric\n",
    "category_properties['value'] = pd.to_numeric(category_properties['value'], errors='coerce')\n",
    "\n",
    "# Drop rows where value is NaN\n",
    "category_properties = category_properties.dropna(subset=['value'])\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "category_properties['timestamp'] = pd.to_datetime(category_properties['timestamp'], unit='ms')\n",
    "\n",
    "# Sort by timestamp and keep the most recent record for each item\n",
    "category_properties = category_properties.sort_values('timestamp').groupby('itemid').last().reset_index()\n",
    "\n",
    "# Map itemid to item_idx\n",
    "category_properties['item_idx'] = category_properties['itemid'].map(item_id_to_idx)\n",
    "\n",
    "# Drop rows where item_idx is NaN\n",
    "category_properties = category_properties.dropna(subset=['item_idx'])\n",
    "category_properties['item_idx'] = category_properties['item_idx'].astype(int)\n",
    "\n",
    "# Select relevant columns\n",
    "item_features = category_properties[['item_idx', 'value']].copy()\n",
    "item_features.columns = ['item_idx', 'categoryid']\n",
    "\n",
    "# Save item features\n",
    "item_features.to_csv(os.path.join(preprocessed_data_dir, \"item_features.csv\"), index=False)\n",
    "print(\"Item features saved:\", item_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Features\n",
    "\n",
    "# I will compute category depths from `category_tree.csv`, to enhance diversity in recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category features saved:    categoryid  depth\n",
      "0         231      0\n",
      "1         791      0\n",
      "2         587      1\n",
      "3         769      2\n",
      "4        1680      2\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate category depth\n",
    "def calculate_depth(category_tree):\n",
    "    depth = {}\n",
    "    \n",
    "    def traverse(node, current_depth):\n",
    "        depth[node] = current_depth\n",
    "        children = category_tree[category_tree['parentid'] == node]['categoryid']\n",
    "        for child in children:\n",
    "            traverse(child, current_depth + 1)\n",
    "    \n",
    "    # Start with root nodes (where parentid is NaN)\n",
    "    root_nodes = category_tree[category_tree['parentid'].isna()]['categoryid']\n",
    "    for root in root_nodes:\n",
    "        traverse(root, 0)\n",
    "    \n",
    "    return depth\n",
    "\n",
    "# Calculate depths\n",
    "category_depths = calculate_depth(category_tree)\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_depths_df = pd.DataFrame(list(category_depths.items()), columns=['categoryid', 'depth'])\n",
    "\n",
    "# Save category features\n",
    "category_depths_df.to_csv(os.path.join(preprocessed_data_dir, \"category_features.csv\"), index=False)\n",
    "print(\"Category features saved:\", category_depths_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary\n",
    "\n",
    "# We have created the following features:\n",
    "# - **User-Item Matrix**: A sparse matrix with shape (number of users, number of items) in `user_item_sparse.pkl`. User and item mappings saved as `user_ids.csv`, `item_ids.csv`.\n",
    "# - **Item Features**: Computed category features, saved as `item_features.csv`.\n",
    "# - **Category Features**: Computed category depths, saved as `category_features.csv`.\n",
    "\n",
    "# These features are ready for collaborative filtering, content-based filtering, and modeling to address all seven business questions.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "# - **Modeling**: Build and evaluate a baseline collaborative filtering model using the user-item interaction matrix.\n",
    "# - **Further Analysis**: Explore content-based filtering and approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
